# Atividade 1: Otimiza√ß√£o com Gradiente Descendente

## Resumo

Este trabalho explora o algoritmo de otimiza√ß√£o **Gradiente Descendente**, uma t√©cnica fundamental em aprendizado de m√°quina e f√≠sica computacional utilizada para encontrar os pontos de m√≠nimo de uma fun√ß√£o. Atrav√©s de uma s√©rie de exerc√≠cios, o comportamento do algoritmo √© investigado em fun√ß√µes de uma e duas dimens√µes, analisando o impacto de par√¢metros cruciais como a **taxa de aprendizado (ùõº)** e a **posi√ß√£o inicial**.

---

### Exerc√≠cio 1: Minimizando uma Fun√ß√£o Quadr√°tica Simples

O primeiro exerc√≠cio consiste em implementar o algoritmo de Gradiente Descendente para encontrar o m√≠nimo da fun√ß√£o convexa $U(x) = x^2 - 1$. A implementa√ß√£o parte de uma posi√ß√£o inicial $x_0 = 5$ e utiliza uma taxa de aprendizado $\alpha = 0.1$. O objetivo √© visualizar a trajet√≥ria da otimiza√ß√£o e entender o efeito dos seus par√¢metros.

**Resultado:**

![Imagem 1](./img/img_1.png)

**An√°lise:**
A trajet√≥ria do algoritmo para encontrar o m√≠nimo de uma fun√ß√£o simples demonstra visualmente o funcionamento do Gradiente Descendente. Partindo de $x_0=5$, cada passo √© dado na dire√ß√£o oposta ao gradiente. O tamanho do passo, definido pela taxa de aprendizado $\alpha$, √© crucial. Um valor de $\alpha$ relativamente alto, como o visto no gr√°fico, pode causar um "overshoot", onde o algoritmo ultrapassa o ponto de m√≠nimo e oscila ao redor dele antes de convergir. A varia√ß√£o deste par√¢metro revela um trade-off fundamental: taxas de aprendizado menores garantem estabilidade, mas exigem mais itera√ß√µes, enquanto taxas maiores podem acelerar a converg√™ncia, mas correm o risco de instabilidade ou diverg√™ncia.

---

### Exerc√≠cio 2: M√≠nimos Locais em um Potencial de Duplo Po√ßo

Nesta etapa, o algoritmo foi aplicado √† fun√ß√£o $U(x) = x^2(x-1)(x+1)$, que possui dois m√≠nimos globais e sim√©tricos. O objetivo foi investigar como a taxa de aprendizado e o ponto inicial afetam a converg√™ncia em uma paisagem n√£o convexa, partindo de $x_0 = 2$.

**Resultado:**

![Imagem 2](./img/img_2.png)

**An√°lise:**
A taxa de aprendizado afeta a trajet√≥ria e para qual m√≠nimo o gradiente descendente vai. Taxas pequenas garantem estabilidade, mas demoram mais. Taxas grandes podem causar salto sobre os m√≠nimos, oscila√ß√µes ou diverg√™ncia.

---

### Exerc√≠cio 3: Efeito de Assimetria no Potencial

O exerc√≠cio anterior foi modificado somando um termo linear, resultando na fun√ß√£o $U(x) = x^2(x-1)(x+1) + x/4$. Esse termo quebra a simetria dos m√≠nimos, tornando um deles globalmente mais baixo que o outro.

**Resultado:**

![Imagem 3](./img/img_3.png)

**An√°lise:**
Ao aumentar o valor de ùõº, pode acontecer *overshooting*, onde os passos passam direto do m√≠nimo e o algoritmo nunca converge. Ele pode come√ßar a oscilar entre os dois lados de um vale. Se o valor for grande demais, o algoritmo pode divergir completamente. Ao diminuir ùõº, os passos s√£o menores, ent√£o o algoritmo leva mais tempo para chegar a um m√≠nimo, por√©m, a trajet√≥ria se torna mais est√°vel e confi√°vel.

---

### Exerc√≠cio 4: Gradiente Descendente em Duas Dimens√µes

O √∫ltimo exerc√≠cio estendeu a an√°lise para a fun√ß√£o de duas vari√°veis, $U(x,y) = \sin(x)\cos(y) + 2(xy)^2/1000$, que possui m√∫ltiplos m√≠nimos locais. A converg√™ncia foi acompanhada atrav√©s de um mapa de contornos e um gr√°fico do valor da fun√ß√£o por itera√ß√£o.

**Resultados:**

![Imagem 4.1](./img/img_4_1.png)

![Imagem 4.2](./img/img_4_2.png)

![Imagem 4.3](./img/img_4_3.png)
**An√°lise:**
Taxas de aprendizado muito altas podem causar diverg√™ncia ou saltos que impedem a converg√™ncia. Taxas muito pequenas tornam o aprendizado est√°vel, mas lento. Devido aos m√∫ltiplos m√≠nimos locais, a posi√ß√£o inicial influencia fortemente para onde o algoritmo converge.

---

### Conclus√£o Geral

A atividade demonstrou de forma pr√°tica as propriedades e limita√ß√µes do algoritmo de Gradiente Descendente. Conclu√≠mos que sua efic√°cia depende criticamente da sintoniza√ß√£o de hiperpar√¢metros, especialmente a **taxa de aprendizado**, que controla o balan√ßo entre velocidade e estabilidade da converg√™ncia. Al√©m disso, ficou evidente que, para fun√ß√µes n√£o convexas, a **posi√ß√£o inicial** √© um fator determinante para o resultado, uma vez que o algoritmo tende a convergir para o m√≠nimo local mais pr√≥ximo, sem garantia de encontrar o m√≠nimo global.